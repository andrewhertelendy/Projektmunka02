{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/37/0k0dl4hj36jg21mcy4dbw89w0000gn/T/ipykernel_70408/2222300173.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
      "/var/folders/37/0k0dl4hj36jg21mcy4dbw89w0000gn/T/ipykernel_70408/2222300173.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineered data saved to 'train_data_engineered.csv' and 'test_data_engineered.csv'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Feature Engineering Class\n",
    "class TrajectoryFeatureEngineering:\n",
    "    def __init__(self, window_size=5):\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def create_kinematic_features(self, df):\n",
    "        \"\"\"Create kinematic features from the input dataframe\"\"\"\n",
    "        # Total velocity and acceleration\n",
    "        df['total_velocity'] = np.sqrt(df['xVelocity']**2 + df['yVelocity']**2).clip(0, 100)\n",
    "        df['total_acceleration'] = np.sqrt(df['xAcceleration']**2 + df['yAcceleration']**2).clip(0, 50)\n",
    "        \n",
    "        # Rate of heading change\n",
    "        df['heading_change_rate'] = df.groupby('trackId')['heading_change'].transform(lambda x: x.diff()).fillna(0).clip(-50, 50)\n",
    "        \n",
    "        # Turning radius\n",
    "        heading_change_safe = np.where(np.abs(df['heading_change']) > 0.001, df['heading_change'], 0.001)\n",
    "        df['turning_radius'] = (df['total_velocity'] / np.abs(heading_change_safe)).clip(0, 1000)\n",
    "        \n",
    "        # Angular velocity\n",
    "        frame_diff = df.groupby('trackId')['frame'].diff().fillna(1)\n",
    "        df['angular_velocity'] = np.abs(df.groupby('trackId')['heading'].diff() / frame_diff).fillna(0).clip(0, 50)\n",
    "    \n",
    "        return df\n",
    "\n",
    "    def create_trajectory_features(self, df):\n",
    "        \"\"\"Create trajectory features using derivatives.\"\"\"\n",
    "        df['dx'] = df.groupby('trackId')['xCenter'].diff().fillna(0)\n",
    "        df['dy'] = df.groupby('trackId')['yCenter'].diff().fillna(0)\n",
    "        df['ddx'] = df.groupby('trackId')['dx'].diff().fillna(0)\n",
    "        df['ddy'] = df.groupby('trackId')['dy'].diff().fillna(0)\n",
    "        \n",
    "        # Curvature\n",
    "        numerator = df['dx'] * df['ddy'] - df['dy'] * df['ddx']\n",
    "        denominator = (df['dx']**2 + df['dy']**2)**(3/2)\n",
    "        denominator = np.where(denominator > 0.001, denominator, 0.001)\n",
    "        df['curvature'] = np.abs(numerator / denominator).clip(0, 100)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def create_statistical_features(self, df):\n",
    "        \"\"\"Create statistical features using rolling windows.\"\"\"\n",
    "        grouped = df.groupby('trackId')\n",
    "        for feature in ['heading_change', 'total_velocity', 'angular_velocity']:\n",
    "            df[f'{feature}_mean'] = grouped[feature].transform(\n",
    "                lambda x: x.rolling(window=self.window_size, center=True, min_periods=1).mean()\n",
    "            ).fillna(0)\n",
    "            df[f'{feature}_std'] = grouped[feature].transform(\n",
    "                lambda x: x.rolling(window=self.window_size, center=True, min_periods=1).std()\n",
    "            ).fillna(0)\n",
    "            df[f'{feature}_max'] = grouped[feature].transform(\n",
    "                lambda x: x.rolling(window=self.window_size, center=True, min_periods=1).max()\n",
    "            ).fillna(0)\n",
    "        return df\n",
    "\n",
    "    def select_features(self, df, feature_columns):\n",
    "        \"\"\"Select relevant features for training\"\"\"\n",
    "        features = [\n",
    "            *feature_columns, # Original features\n",
    "            'total_velocity', 'total_acceleration', 'heading_change_rate', 'turning_radius', 'angular_velocity',  # New kinematic\n",
    "            'curvature', # Trajectory\n",
    "            'heading_change_mean', 'heading_change_std', 'heading_change_max', # Statistical\n",
    "            'total_velocity_mean', 'total_velocity_std', 'total_velocity_max',\n",
    "            'angular_velocity_mean', 'angular_velocity_std', 'angular_velocity_max',\n",
    "            'turn_binary'\n",
    "        ]\n",
    "        return df[features]\n",
    "        \n",
    "    def smooth_features(self, df):\n",
    "        \"\"\"Apply Savitzky-Golay filter to smooth kinematic features.\"\"\"\n",
    "        grouped = df.groupby('trackId')\n",
    "        \n",
    "        for feature in ['total_velocity', 'total_acceleration', 'heading_change_rate', 'angular_velocity']:\n",
    "          df[feature] = grouped[feature].transform(lambda x: signal.savgol_filter(x, window_length=5, polyorder=2, mode='nearest'))\n",
    "        return df\n",
    "    \n",
    "    def scale_features(self, df):\n",
    "        \"\"\"Scale features using RobustScaler.\"\"\"\n",
    "        scaler = RobustScaler()\n",
    "        numerical_cols = df.select_dtypes(include=np.number).columns\n",
    "        df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "        return df\n",
    "\n",
    "    def process(self, df, feature_columns):\n",
    "        \"\"\"Main processing function\"\"\"\n",
    "        df = self.create_kinematic_features(df)\n",
    "        df = self.create_trajectory_features(df)\n",
    "        df = self.create_statistical_features(df)\n",
    "        df = self.smooth_features(df)\n",
    "        df = self.select_features(df, feature_columns)\n",
    "        df = self.scale_features(df)\n",
    "        return df\n",
    "\n",
    "# Main execution\n",
    "if __name__ == '__main__':\n",
    "  # Load processed data\n",
    "    train_data = pd.read_csv('train_data_processed.csv')\n",
    "    test_data = pd.read_csv('test_data_processed.csv')\n",
    "    feature_columns = [col for col in train_data.columns if col not in ['turn_binary', 'turn_label', 'file_id']]\n",
    "  \n",
    "  # Feature engineering\n",
    "    feature_engineer = TrajectoryFeatureEngineering()\n",
    "    train_data_engineered = feature_engineer.process(train_data, feature_columns)\n",
    "    test_data_engineered = feature_engineer.process(test_data, feature_columns)\n",
    "  \n",
    "  # Save engineered data\n",
    "    train_data_engineered.to_csv('train_data_engineered.csv', index=False)\n",
    "    test_data_engineered.to_csv('test_data_engineered.csv', index=False)\n",
    "    print(\"Engineered data saved to 'train_data_engineered.csv' and 'test_data_engineered.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
